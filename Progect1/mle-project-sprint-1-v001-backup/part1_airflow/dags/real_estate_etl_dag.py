import logging
import pandas as pd
import pendulum
from airflow.decorators import dag, task
from airflow.providers.postgres.hooks.postgres import PostgresHook
from sqlalchemy import create_engine, text
from dotenv import load_dotenv

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è 25
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dag(
    schedule_interval="@once",
    start_date=pendulum.datetime(2024, 1, 1, tz="UTC"),
    catchup=False,
    tags=["real_estate"],
)
def real_estate_etl():

    @task
    def create_table():
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
        hook = PostgresHook('destination_db')
        conn = None
        try:
            conn = hook.get_conn()
            logger.info("‚úÖ –£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
            raise
        
        engine = create_engine(hook.get_uri())
        with engine.connect() as conn:
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS real_estate_dataset (
                    flat_id INT PRIMARY KEY,
                    building_id INT,
                    floor INT,
                    kitchen_area FLOAT,
                    living_area FLOAT,
                    rooms INT,
                    is_apartment BOOLEAN,
                    studio BOOLEAN,
                    total_area FLOAT,
                    price FLOAT,
                    build_year INT,
                    building_type_int INT,
                    latitude FLOAT,
                    longitude FLOAT,
                    ceiling_height FLOAT,
                    flats_count INT,
                    floors_total INT,
                    has_elevator BOOLEAN
                );
            """))
            logger.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ —Å–æ–∑–¥–∞–Ω–∞")

    @task
    def extract_data() -> pd.DataFrame:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
        hook = PostgresHook('destination_db')
        conn = None
        try:
            conn = hook.get_conn()
            logger.info("‚úÖ –£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise

        query = """
            SELECT 
                f.id as flat_id,
                f.building_id,
                f.floor,
                f.kitchen_area,
                f.living_area,
                f.rooms,
                f.is_apartment,
                f.studio,
                f.total_area,
                f.price,
                b.build_year,
                b.building_type_int,
                b.latitude,
                b.longitude,
                b.ceiling_height,
                b.flats_count,
                b.floors_total,
                b.has_elevator
            FROM flats f
            LEFT JOIN buildings b ON f.building_id = b.id
        """
        df = pd.read_sql(query, conn)
        logger.info("üì• –ò–∑–≤–ª–µ—á–µ–Ω–æ —Å—Ç—Ä–æ–∫: %d", len(df))
        return df

    @task
    def transform_data(df: pd.DataFrame) -> pd.DataFrame:
        """–û—á–∏—Å—Ç–∫–∞ –∏ –±–∞–∑–æ–≤–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö."""
        df = df.convert_dtypes()
        df['has_elevator'] = df['has_elevator'].fillna(False)
        logger.info("üîß –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        return df

    @task
    def load_data(df: pd.DataFrame):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ—á–∏—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö."""
        hook = PostgresHook('destination_db')
        engine = None
        try:
            engine = create_engine(hook.get_uri())
            logger.info("‚úÖ –£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            raise

        df.to_sql(
            'real_estate_dataset',
            engine,
            if_exists='replace',
            index=False,
            method='multi',
            chunksize=1000
        )
        logger.info("üì§ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –ë–î")

    # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á –≤ DAG
    create_table_task = create_table()
    df = extract_data()
    cleaned_df = transform_data(df)
    load_data(cleaned_df)

# –°–æ–∑–¥–∞–Ω–∏–µ DAG
dag = real_estate_etl()